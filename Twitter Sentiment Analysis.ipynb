{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "965bf207-9e3f-4bdf-86d5-958b025d5e3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tweepy in c:\\users\\bharg\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (4.10.1)\n",
      "Requirement already satisfied: requests<3,>=2.27.0 in c:\\users\\bharg\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tweepy) (2.28.1)\n",
      "Requirement already satisfied: oauthlib<4,>=3.2.0 in c:\\users\\bharg\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tweepy) (3.2.1)\n",
      "Requirement already satisfied: requests-oauthlib<2,>=1.2.0 in c:\\users\\bharg\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tweepy) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\bharg\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.27.0->tweepy) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\bharg\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.27.0->tweepy) (1.26.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\bharg\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.27.0->tweepy) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\bharg\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.27.0->tweepy) (2022.9.24)\n",
      "Requirement already satisfied: textblob in c:\\users\\bharg\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.17.1)\n",
      "Requirement already satisfied: nltk>=3.1 in c:\\users\\bharg\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from textblob) (3.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\bharg\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk>=3.1->textblob) (1.2.0)\n",
      "Requirement already satisfied: click in c:\\users\\bharg\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk>=3.1->textblob) (8.1.3)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\bharg\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk>=3.1->textblob) (2022.9.13)\n",
      "Requirement already satisfied: tqdm in c:\\users\\bharg\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk>=3.1->textblob) (4.64.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\bharg\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from click->nltk>=3.1->textblob) (0.4.5)\n",
      "Requirement already satisfied: wordcloud in c:\\users\\bharg\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.8.2.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\bharg\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from wordcloud) (3.6.1)\n",
      "Requirement already satisfied: numpy>=1.6.1 in c:\\users\\bharg\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from wordcloud) (1.23.4)\n",
      "Requirement already satisfied: pillow in c:\\users\\bharg\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from wordcloud) (9.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\bharg\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->wordcloud) (3.0.9)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\bharg\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->wordcloud) (1.4.4)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\bharg\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->wordcloud) (4.37.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\bharg\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->wordcloud) (1.0.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\bharg\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->wordcloud) (21.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\bharg\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->wordcloud) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\bharg\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->wordcloud) (0.11.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\bharg\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->wordcloud) (1.16.0)\n",
      "Requirement already satisfied: nltk in c:\\users\\bharg\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.7)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\bharg\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk) (2022.9.13)\n",
      "Requirement already satisfied: tqdm in c:\\users\\bharg\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk) (4.64.1)\n",
      "Requirement already satisfied: click in c:\\users\\bharg\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk) (8.1.3)\n",
      "Requirement already satisfied: joblib in c:\\users\\bharg\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\bharg\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from click->nltk) (0.4.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install tweepy\n",
    "!pip install textblob\n",
    "!pip install wordcloud\n",
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "001d2bb0-908a-4750-9e53-2cafa203d74e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\bharg\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\bharg\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\bharg\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\bharg\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import tweepy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from textblob import TextBlob\n",
    "from wordcloud import WordCloud\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f56795c-38ec-4d2a-9bce-49929a9796dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "colNames = ['target', 'id', 'date','flag','user','text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a49730f9-b969-4122-b3b9-939b90397a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "originalDataDF = pd.read_csv('data/tweet_data.csv', names=colNames, delimiter=',' ,engine='python', nrows=None, encoding='latin-1', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f55b5e7-c313-4e14-9590-2aad7086121b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target          id                          date      flag  \\\n",
       "0       0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
       "1       0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "2       0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "3       0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4       0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "\n",
       "              user                                               text  \n",
       "0  _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
       "1    scotthamilton  is upset that he can't update his Facebook by ...  \n",
       "2         mattycus  @Kenichan I dived many times for the ball. Man...  \n",
       "3          ElleCTF    my whole body feels itchy and like its on fire   \n",
       "4           Karoli  @nationwideclass no, it's not behaving at all....  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "originalDataDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0732484f-7602-40a9-a6ff-d1627a54f468",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1600000, 6)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "originalDataDF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9097dd7d-54a5-4cdf-88c5-344dff47daf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9600000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "originalDataDF.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fd4f9b9-981e-4708-96ef-1fedc9b0d4ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
       "1          is upset that he can't update his Facebook by ...\n",
       "2          @Kenichan I dived many times for the ball. Man...\n",
       "3            my whole body feels itchy and like its on fire \n",
       "4          @nationwideclass no, it's not behaving at all....\n",
       "                                 ...                        \n",
       "1599995    Just woke up. Having no school is the best fee...\n",
       "1599996    TheWDB.com - Very cool to hear old Walt interv...\n",
       "1599997    Are you ready for your MoJo Makeover? Ask me f...\n",
       "1599998    Happy 38th Birthday to my boo of alll time!!! ...\n",
       "1599999    happy #charitytuesday @theNSPCC @SparksCharity...\n",
       "Name: text, Length: 1600000, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "originalDataDF['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923056aa-53ff-42ef-8fb8-59e26166a69d",
   "metadata": {},
   "source": [
    "# Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3b8739b-ae3f-4c20-b90a-0db1e9bc56d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handling_emojis(text):\n",
    "    # Smile -- :), : ), :-), (:, ( :, (-:, :')\n",
    "    text = re.sub(r'(:\\s?\\)|:-\\)|\\(\\s?:|\\(-:|:\\'\\))', ' EMO_POS ', text)\n",
    "    # Laugh -- :D, : D, :-D, xD, x-D, XD, X-D\n",
    "    text = re.sub(r'(:\\s?D|:-D|x-?D|X-?D)', ' EMO_POS ', text)\n",
    "    # Love -- <3, :*\n",
    "    text = re.sub(r'(<3|:\\*)', ' EMO_POS ', text)\n",
    "    # Wink -- ;-), ;), ;-D, ;D, (;,  (-;\n",
    "    text = re.sub(r'(;-?\\)|;-?D|\\(-?;)', ' EMO_POS ', text)\n",
    "    # Sad -- :-(, : (, :(, ):, )-:\n",
    "    text = re.sub(r'(:\\s?\\(|:-\\(|\\)\\s?:|\\)-:)', ' EMO_NEG ', text)\n",
    "    # Cry -- :,(, :'(, :\"(\n",
    "    text = re.sub(r'(:,\\(|:\\'\\(|:\"\\()', ' EMO_NEG ', text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3507b2e7-38cc-464b-af6c-ff44f76cfc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning the text\n",
    "\n",
    "# removing tagged username '@'\n",
    "def cleaningText(text):\n",
    "    text = text.strip('\\'\"?!,.():;') # removing punctuation\n",
    "    text = re.sub(r'(.)\\1+', r'\\1\\1', text) # convert more than 2 letter repetitions to 2 letter #fooood -> food\n",
    "    text = re.sub(r'(-|\\')','',text) # removing additional -& '\n",
    "    text = re.sub(r'@[A-Za-z0-9]+','',text) #removing @usernames\n",
    "    text = re.sub(r'#','',text) #removing '#' symbols\n",
    "    text = re.sub(r'RT[\\s]+','',text) #removes RT(Re-Tweet) string \n",
    "    text = re.sub(r'https?:\\/\\/\\S+','',text) #removing the hyperlink\n",
    "    text = re.sub(r'((www\\.[\\S]+)|(https?://[\\S]+))', '', text) #removing urls\n",
    "    # Replace 2+ dots with space\n",
    "    text = re.sub(r'\\.{2,}', ' ', text)\n",
    "    # Strip space, \" and ' from tweet\n",
    "    text = text.strip(' \"\\'')\n",
    "    # Replace emojis with either EMO_POS or EMO_NEG\n",
    "    text = handling_emojis(text)\n",
    "    # Replace multiple spaces with a single space\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = text.lower() #make the text to lowercase\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3df51804-ae13-4538-b2c1-c9f013ff6274",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aww, thats a bummer. you shoulda got david carr of third day to do it. emo_pos '"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "originalDataDF['text'] = originalDataDF['text'].apply(cleaningText)\n",
    "originalDataDF['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "391b2b99-1d55-4a7a-a0ec-50dffc176237",
   "metadata": {},
   "outputs": [],
   "source": [
    "contractionWords = {\n",
    "\"aren’t\":\"are not\",\"can’t\":\"can not\",\"couldn’t\":\"could not \",\"didn’t\":\"did not\",\"doesn’t\":\"does not\",\"don’t\":\"do not\",\"hadn’t\":\"had not\",\"hasn’t\":\"has not \",\"haven’t\":\"have not\",\n",
    "\"I’m\":\"I am\",\"I’ve\":\"I have\",\"isn’t\":\"is not\",\"let’s\":\"let us\",\"mightn’t\":\"might not\",\"mustn’t\":\"must not\",\"shan’t\":\"shall not\",\"shouldn’t\":\"should not\",\"that’s\":\" that is\",\"he’ll\":\" he will\",\n",
    "\"I’ll\":\"I will\",\"she’ll\":\"she will\",\"she’s\":\"she is\",\"there’s\":\"there is\",\"they’ll\":\" they will\",\"they’re\":\"they are\",\"they’ve\":\"they have\",\"we’re\":\"we are\",\"we’ve\":\"we have\",\"weren’t\":\"were not\",\n",
    "\"what’ll\":\"what will\",\"what’re\":\"what are\",\"what’ve\":\"what have\",\"where’s\":\"where is\",\"who’d\":\"who would\",\"who’ll\":\"who will\",\"who’re\":\"who are\",\"who’s\":\"who is\",\"who’ve\":\"who have\",\"won’t\":\"will not\",\n",
    "\"wouldn’t\":\"would not\",\"you’d\":\"you would\",\"you’re\":\"you are\",\"you’ve\":\"you have\",\"it’s\":\"it is\",\"wasn't\":\"was not\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "13a2d884-7bd7-4ff6-bfa5-ed66d75a74ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# negation handling\n",
    "def negationHandling(text):\n",
    "    words = text.split()\n",
    "    temp = [contractionWords[word] if word in contractionWords else word for word in words]\n",
    "    temp = \" \".join(temp)\n",
    "    return temp\n",
    "originalDataDF['text'] = originalDataDF['text'].apply(negationHandling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6cdf1be7-e383-4755-a424-86e2d3db6b4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aww',\n",
       " ',',\n",
       " 'thats',\n",
       " 'a',\n",
       " 'bummer',\n",
       " '.',\n",
       " 'you',\n",
       " 'shoulda',\n",
       " 'got',\n",
       " 'david',\n",
       " 'carr',\n",
       " 'of',\n",
       " 'third',\n",
       " 'day',\n",
       " 'to',\n",
       " 'do',\n",
       " 'it',\n",
       " '.',\n",
       " 'emo_pos']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_set = []\n",
    "def wordTokenize(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    return tokens\n",
    "originalDataDF['text'] = originalDataDF['text'].apply(wordTokenize)\n",
    "originalDataDF['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "19be6ab9-9034-4792-80f6-52109117563e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aww',\n",
       " ',',\n",
       " 'thats',\n",
       " 'bummer',\n",
       " '.',\n",
       " 'shoulda',\n",
       " 'got',\n",
       " 'david',\n",
       " 'carr',\n",
       " 'third',\n",
       " 'day',\n",
       " '.',\n",
       " 'emo_pos']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "def removeStopWords(tokens):\n",
    "    temp = [word for word in tokens if word not in stop_words]\n",
    "    return temp\n",
    "originalDataDF['text'] = originalDataDF['text'].apply(removeStopWords)\n",
    "originalDataDF['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4d2d4856-cb73-4472-9aa2-df2395ac5bcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aww', 'thats', 'bummer', 'shoulda', 'got', 'david', 'carr', 'third', 'day']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def removeUnnecessaryChars(tokens):\n",
    "    temp = [word for word in tokens if word.isalpha()]\n",
    "    return temp\n",
    "originalDataDF['text'] = originalDataDF['text'].apply(removeUnnecessaryChars)\n",
    "originalDataDF['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac476a32-79da-466d-9667-5dd5552353e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b04915e-2739-44e2-8234-d6f531d657ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma = WordNetLemmatizer()\n",
    "def lemmatizeTweets(wordList):\n",
    "    temp = []\n",
    "    for word in wordList:\n",
    "        _word = lemma.lemmatize(word)\n",
    "        temp.append(_word)\n",
    "    return ' '.join(temp)\n",
    "originalDataDF['text'] = originalDataDF['text'].apply(lemmatizeTweets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "221fb56c-7d32-463e-a75d-70b4aa662ef9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'whole body feel itchy like fire'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "originalDataDF['text'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a9c244ce-d000-4b56-ba32-8d30b2f2653a",
   "metadata": {},
   "outputs": [],
   "source": [
    "requiredTweetData = originalDataDF[[\"target\",\"text\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b2b9f212-898c-4d94-a93b-a69e35c90fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Taking sample data for vectorization\n",
    "requiredTweetData = requiredTweetData[700000:900000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aacbd347-3961-4e6b-bfe7-ade13944d621",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "word_set = []\n",
    "\n",
    "for sent in requiredTweetData['text']:\n",
    "    temp = [i for i in word_tokenize(sent)]\n",
    "    sentences.append(temp)\n",
    "    for word in temp:\n",
    "        if word not in word_set:\n",
    "            word_set.append(word)\n",
    "            \n",
    "word_set = set(word_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "58dd8f1d-00b4-4056-9255-028917b61f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for word in :\n",
    "#         if word not in word_set:\n",
    "#             word_set.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d4d64703-ccd3-4331-9f73-9befb0e7cf22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for sent in requiredTweetData['text']:\n",
    "#     for word in sent:\n",
    "#         if word not in word_set:\n",
    "#             word_set.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1ac4569f-7673-4707-b654-edb219f3de41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'reoccuring',\n",
       " 'recognized',\n",
       " 'ofcooz',\n",
       " 'evtime',\n",
       " 'cozyy',\n",
       " 'tennents',\n",
       " 'henie',\n",
       " 'mcnuggets',\n",
       " 'mucvhly',\n",
       " 'diis',\n",
       " 'gizmodo',\n",
       " 'impudent',\n",
       " 'mgmt',\n",
       " 'niggasz',\n",
       " 'eevil',\n",
       " 'suzi',\n",
       " 'manchester',\n",
       " 'ayee',\n",
       " 'ctrl',\n",
       " 'nmd',\n",
       " 'controversal',\n",
       " 'reasonn',\n",
       " 'jacked',\n",
       " 'afternon',\n",
       " 'daraas',\n",
       " 'badbum',\n",
       " 'buttered',\n",
       " 'tourning',\n",
       " 'outdoor',\n",
       " 'knowwe',\n",
       " 'sheit',\n",
       " 'roadster',\n",
       " 'xplane',\n",
       " 'nonee',\n",
       " 'develops',\n",
       " 'hommerton',\n",
       " 'technicality',\n",
       " 'accordng',\n",
       " 'gainin',\n",
       " 'nuckvatar',\n",
       " 'pax',\n",
       " 'humpf',\n",
       " 'cremes',\n",
       " 'plagiarism',\n",
       " 'hostin',\n",
       " 'moobs',\n",
       " 'scooby',\n",
       " 'mindblowing',\n",
       " 'gassing',\n",
       " 'bungalow',\n",
       " 'denon',\n",
       " 'straightened',\n",
       " 'fraguaers',\n",
       " 'pumpin',\n",
       " 'oolainy',\n",
       " 'yves',\n",
       " 'hardd',\n",
       " 'poster',\n",
       " 'bracknell',\n",
       " 'euggh',\n",
       " 'updateswise',\n",
       " 'sweetie',\n",
       " 'yelana',\n",
       " 'gomtv',\n",
       " 'neah',\n",
       " 'znatrainer',\n",
       " 'rosales',\n",
       " 'takeoff',\n",
       " 'pema',\n",
       " 'cleaaning',\n",
       " 'clifton',\n",
       " 'massachusetts',\n",
       " 'caseys',\n",
       " 'marshfield',\n",
       " 'balckcurrant',\n",
       " 'afters',\n",
       " 'nifty',\n",
       " 'eeeww',\n",
       " 'adapter',\n",
       " 'demetres',\n",
       " 'nlaws',\n",
       " 'goddammit',\n",
       " 'insisting',\n",
       " 'siong',\n",
       " 'gigapixel',\n",
       " 'shana',\n",
       " 'perk',\n",
       " 'gilad',\n",
       " 'iteration',\n",
       " 'testen',\n",
       " 'hours',\n",
       " 'taketh',\n",
       " 'artie',\n",
       " 'detatch',\n",
       " 'doeth',\n",
       " 'boredum',\n",
       " 'savanah',\n",
       " 'nighttime',\n",
       " 'ooo',\n",
       " 'dealership',\n",
       " 'duvet',\n",
       " 'atmedia',\n",
       " 'loudspeaker',\n",
       " 'affordable',\n",
       " 'pongo',\n",
       " 'fairr',\n",
       " 'nori',\n",
       " 'constitutional',\n",
       " 'fiucs',\n",
       " 'mrtribble',\n",
       " 'tdd',\n",
       " 'perry',\n",
       " 'dawnn',\n",
       " 'marie',\n",
       " 'collie',\n",
       " 'dennys',\n",
       " 'churros',\n",
       " 'despereaux',\n",
       " 'ssds',\n",
       " 'gian',\n",
       " 'glorious',\n",
       " 'owt',\n",
       " 'pleeasee',\n",
       " 'eas',\n",
       " 'realitytv',\n",
       " 'sugargliders',\n",
       " 'branching',\n",
       " 'eesshh',\n",
       " 'ceasars',\n",
       " 'wasup',\n",
       " 'protagonist',\n",
       " 'frasers',\n",
       " 'splurge',\n",
       " 'em',\n",
       " 'rida',\n",
       " 'coordinated',\n",
       " 'negelcted',\n",
       " 'faltam',\n",
       " 'cvc',\n",
       " 'frutista',\n",
       " 'replyy',\n",
       " 'legnth',\n",
       " 'mcarthy',\n",
       " 'thourockit',\n",
       " 'acl',\n",
       " 'learly',\n",
       " 'rebooted',\n",
       " 'overlay',\n",
       " 'frattini',\n",
       " 'sterio',\n",
       " 'giampaolo',\n",
       " 'dresden',\n",
       " 'mgr',\n",
       " 'tiredgonna',\n",
       " 'askd',\n",
       " 'jaeger',\n",
       " 'gawwd',\n",
       " 'frost',\n",
       " 'rung',\n",
       " 'took',\n",
       " 'cala',\n",
       " 'undesirable',\n",
       " 'ubunti',\n",
       " 'lessions',\n",
       " 'sexii',\n",
       " 'swoop',\n",
       " 'thirst',\n",
       " 'mondjuk',\n",
       " 'sebz',\n",
       " 'eiscafe',\n",
       " 'hiyaa',\n",
       " 'frieday',\n",
       " 'twollowed',\n",
       " 'democratic',\n",
       " 'ficamme',\n",
       " 'bohr',\n",
       " 'rawepicurean',\n",
       " 'tropez',\n",
       " 'flickring',\n",
       " 'sku',\n",
       " 'scarf',\n",
       " 'everybit',\n",
       " 'profileyour',\n",
       " 'sianz',\n",
       " 'tequila',\n",
       " 'unlaws',\n",
       " 'harharhar',\n",
       " 'dubious',\n",
       " 'hogaeen',\n",
       " 'velasco',\n",
       " 'hijack',\n",
       " 'bigtime',\n",
       " 'authen',\n",
       " 'dibrunos',\n",
       " 'iga',\n",
       " 'front',\n",
       " 'lubbock',\n",
       " 'kpn',\n",
       " 'elevato',\n",
       " 'conley',\n",
       " 'scrumbledeggs',\n",
       " 'namedropping',\n",
       " 'gbig',\n",
       " 'rosco',\n",
       " 'shreveport',\n",
       " 'hatalmas',\n",
       " 'seperation',\n",
       " 'vince',\n",
       " 'cappucino',\n",
       " 'perky',\n",
       " 'bien',\n",
       " 'breed',\n",
       " 'zoozoos',\n",
       " 'dolla',\n",
       " 'forthwith',\n",
       " 'archana',\n",
       " 'punt',\n",
       " 'rba',\n",
       " 'lyme',\n",
       " 'smidge',\n",
       " 'tinglish',\n",
       " 'wentz',\n",
       " 'isjust',\n",
       " 'divenenineney',\n",
       " 'luh',\n",
       " 'haay',\n",
       " 'severe',\n",
       " 'homealone',\n",
       " 'flml',\n",
       " 'drugging',\n",
       " 'awesime',\n",
       " 'ittle',\n",
       " 'mochiatta',\n",
       " 'tearoom',\n",
       " 'choy',\n",
       " 'malapit',\n",
       " 'carradines',\n",
       " 'fundraise',\n",
       " 'uncross',\n",
       " 'studio',\n",
       " 'brutal',\n",
       " 'strategic',\n",
       " 'renfrew',\n",
       " 'automatica',\n",
       " 'pattons',\n",
       " 'hoodwink',\n",
       " 'scared',\n",
       " 'capcom',\n",
       " 'shoppinng',\n",
       " 'dan',\n",
       " 'hive',\n",
       " 'sanded',\n",
       " 'bumbumbumeer',\n",
       " 'gregwhorey',\n",
       " 'mush',\n",
       " 'amb',\n",
       " 'aute',\n",
       " 'bxtch',\n",
       " 'smoothly',\n",
       " 'sneakily',\n",
       " 'thankfully',\n",
       " 'amplives',\n",
       " 'singularity',\n",
       " 'quickoffice',\n",
       " 'pugsly',\n",
       " 'unles',\n",
       " 'oxfordgirl',\n",
       " 'sprack',\n",
       " 'attent',\n",
       " 'moneyball',\n",
       " 'glammed',\n",
       " 'plp',\n",
       " 'laziness',\n",
       " 'lkdf',\n",
       " 'magabounce',\n",
       " 'spinachnoodle',\n",
       " 'cutaway',\n",
       " 'dylanlive',\n",
       " 'cheesesteaks',\n",
       " 'stepbrother',\n",
       " 'slining',\n",
       " 'verified',\n",
       " 'mui',\n",
       " 'distribution',\n",
       " 'hho',\n",
       " 'planeyikes',\n",
       " 'koulalalompour',\n",
       " 'mirror',\n",
       " 'spongbob',\n",
       " 'invade',\n",
       " 'probation',\n",
       " 'everyhting',\n",
       " 'computerarts',\n",
       " 'mumy',\n",
       " 'sillywilly',\n",
       " 'ellu',\n",
       " 'astounded',\n",
       " 'wendis',\n",
       " 'vlogs',\n",
       " 'aunke',\n",
       " 'allocation',\n",
       " 'mke',\n",
       " 'meco',\n",
       " 'meezers',\n",
       " 'crazyy',\n",
       " 'runned',\n",
       " 'reminded',\n",
       " 'sinigang',\n",
       " 'muey',\n",
       " 'nosh',\n",
       " 'neue',\n",
       " 'nahi',\n",
       " 'exbarnet',\n",
       " 'karantina',\n",
       " 'bangle',\n",
       " 'buscando',\n",
       " 'seren',\n",
       " 'lippyprint',\n",
       " 'ware',\n",
       " 'masungit',\n",
       " 'birthdaay',\n",
       " 'damanged',\n",
       " 'spontaneously',\n",
       " 'stokkedd',\n",
       " 'steamer',\n",
       " 'whackk',\n",
       " 'caprica',\n",
       " 'hwaa',\n",
       " 'grammys',\n",
       " 'jaunt',\n",
       " 'dunham',\n",
       " 'mosst',\n",
       " 'lbaq',\n",
       " 'multiple',\n",
       " 'jannet',\n",
       " 'wrkn',\n",
       " 'doke',\n",
       " 'cinima',\n",
       " 'fantabulous',\n",
       " 'ruin',\n",
       " 'biatch',\n",
       " 'charmin',\n",
       " 'eenie',\n",
       " 'trvsday',\n",
       " 'juanzkeez',\n",
       " 'laughed',\n",
       " 'iono',\n",
       " 'babynes',\n",
       " 'zi',\n",
       " 'nuthn',\n",
       " 'enitre',\n",
       " 'staing',\n",
       " 'dyspraxia',\n",
       " 'verybadman',\n",
       " 'rendlesham',\n",
       " 'ichat',\n",
       " 'trusty',\n",
       " 'chuc',\n",
       " 'mex',\n",
       " 'publicwhip',\n",
       " 'sumitra',\n",
       " 'amiright',\n",
       " 'th',\n",
       " 'professor',\n",
       " 'runn',\n",
       " 'waterslides',\n",
       " 'blogbank',\n",
       " 'gash',\n",
       " 'antirain',\n",
       " 'dreamcast',\n",
       " 'nantwich',\n",
       " 'paddlepops',\n",
       " 'keltie',\n",
       " 'nexxt',\n",
       " 'possum',\n",
       " 'sentra',\n",
       " 'novoseek',\n",
       " 'wondder',\n",
       " 'squarespac',\n",
       " 'clubbin',\n",
       " 'wrx',\n",
       " 'supportbeen',\n",
       " 'footrest',\n",
       " 'buzzer',\n",
       " 'webradio',\n",
       " 'lexington',\n",
       " 'farsi',\n",
       " 'exausto',\n",
       " 'bassnectar',\n",
       " 'skes',\n",
       " 'sortofit',\n",
       " 'yhats',\n",
       " 'unusal',\n",
       " 'calzone',\n",
       " 'siickly',\n",
       " 'riitte',\n",
       " 'trishina',\n",
       " 'idt',\n",
       " 'kaise',\n",
       " 'martinithe',\n",
       " 'outdoors',\n",
       " 'sicklee',\n",
       " 'indys',\n",
       " 'sible',\n",
       " 'ev',\n",
       " 'pasadena',\n",
       " 'worldvision',\n",
       " 'bedrest',\n",
       " 'lokesh',\n",
       " 'make',\n",
       " 'eerr',\n",
       " 'staes',\n",
       " 'embarassed',\n",
       " 'plugin',\n",
       " 'jaadu',\n",
       " 'confused',\n",
       " 'yolanda',\n",
       " 'apsaloutly',\n",
       " 'manifesto',\n",
       " 'lycans',\n",
       " 'ingat',\n",
       " 'transmogrified',\n",
       " 'karan',\n",
       " 'aftertour',\n",
       " 'pussyy',\n",
       " 'dressy',\n",
       " 'homeoffice',\n",
       " 'freaking',\n",
       " 'incessantly',\n",
       " 'turnitin',\n",
       " 'peaceful',\n",
       " 'spotifys',\n",
       " 'neva',\n",
       " 'xoxoxoxo',\n",
       " 'bellaitalia',\n",
       " 'scott',\n",
       " 'mahasha',\n",
       " 'mild',\n",
       " 'caley',\n",
       " 'ruehl',\n",
       " 'iwanna',\n",
       " 'overhere',\n",
       " 'lovebox',\n",
       " 'checkin',\n",
       " 'erm',\n",
       " 'onme',\n",
       " 'fortyhands',\n",
       " 'tonihgt',\n",
       " 'tuba',\n",
       " 'landid',\n",
       " 'dnn',\n",
       " 'royice',\n",
       " 'casbah',\n",
       " 'yonder',\n",
       " 'eyeing',\n",
       " 'distance',\n",
       " 'ok',\n",
       " 'missin',\n",
       " 'avil',\n",
       " 'testtweet',\n",
       " 'nak',\n",
       " 'neatly',\n",
       " 'harford',\n",
       " 'flyn',\n",
       " 'lyiin',\n",
       " 'tthat',\n",
       " 'elevate',\n",
       " 'muisc',\n",
       " 'saxony',\n",
       " 'legacy',\n",
       " 'haaha',\n",
       " 'socalled',\n",
       " 'amoore',\n",
       " 'endofyear',\n",
       " 'popsicle',\n",
       " 'lunchh',\n",
       " 'namular',\n",
       " 'throttlovat',\n",
       " 'convincingly',\n",
       " 'twiiters',\n",
       " 'munchie',\n",
       " 'ipl',\n",
       " 'yippee',\n",
       " 'uk',\n",
       " 'slumber',\n",
       " 'pioneer',\n",
       " 'bludd',\n",
       " 'indie',\n",
       " 'bremen',\n",
       " 'yourenot',\n",
       " 'roshan',\n",
       " 'biocch',\n",
       " 'intimadating',\n",
       " 'baldwin',\n",
       " 'raping',\n",
       " 'souvenir',\n",
       " 'blogdesk',\n",
       " 'cheapie',\n",
       " 'sicknastyy',\n",
       " 'checkbook',\n",
       " 'nonbreaking',\n",
       " 'planter',\n",
       " 'balm',\n",
       " 'homeworking',\n",
       " 'unc',\n",
       " 'tramici',\n",
       " 'brennas',\n",
       " 'shekinah',\n",
       " 'respective',\n",
       " 'tudung',\n",
       " 'leakycon',\n",
       " 'restretch',\n",
       " 'camo',\n",
       " 'islelin',\n",
       " 'undeliverable',\n",
       " 'flymo',\n",
       " 'flirted',\n",
       " 'terrance',\n",
       " 'kt',\n",
       " 'undestand',\n",
       " 'patric',\n",
       " 'amna',\n",
       " 'kliatan',\n",
       " 'topless',\n",
       " 'akin',\n",
       " 'deden',\n",
       " 'sweete',\n",
       " 'cinderalla',\n",
       " 'ballfields',\n",
       " 'moniker',\n",
       " 'regelen',\n",
       " 'koi',\n",
       " 'throw',\n",
       " 'stoned',\n",
       " 'perfectly',\n",
       " 'convoluted',\n",
       " 'onaim',\n",
       " 'showoff',\n",
       " 'unfortch',\n",
       " 'veet',\n",
       " 'tggl',\n",
       " 'breathsavers',\n",
       " 'commutebox',\n",
       " 'theemm',\n",
       " 'wilmslow',\n",
       " 'afterball',\n",
       " 'fido',\n",
       " 'brr',\n",
       " 'hook',\n",
       " 'statue',\n",
       " 'tiresome',\n",
       " 'lemi',\n",
       " 'construction',\n",
       " 'seres',\n",
       " 'tstrap',\n",
       " 'awsomee',\n",
       " 'tab',\n",
       " 'kantion',\n",
       " 'killaz',\n",
       " 'sentence',\n",
       " 'vpn',\n",
       " 'somethiing',\n",
       " 'kidnap',\n",
       " 'wasnts',\n",
       " 'kindy',\n",
       " 'junee',\n",
       " 'musicinoursoul',\n",
       " 'donkeykong',\n",
       " 'refilling',\n",
       " 'cuzins',\n",
       " 'organized',\n",
       " 'chantelle',\n",
       " 'jang',\n",
       " 'pedure',\n",
       " 'interweb',\n",
       " 'youer',\n",
       " 'dugout',\n",
       " 'schenectady',\n",
       " 'ecspecially',\n",
       " 'misfortune',\n",
       " 'wickedness',\n",
       " 'formernewexco',\n",
       " 'deafen',\n",
       " 'howth',\n",
       " 'quantifiable',\n",
       " 'nanood',\n",
       " 'qb',\n",
       " 'ivy',\n",
       " 'thig',\n",
       " 'jizzem',\n",
       " 'annoucement',\n",
       " 'joon',\n",
       " 'anoying',\n",
       " 'togo',\n",
       " 'youve',\n",
       " 'pastoral',\n",
       " 'metadata',\n",
       " 'uri',\n",
       " 'blowoff',\n",
       " 'cemetery',\n",
       " 'stellans',\n",
       " 'bangin',\n",
       " 'brom',\n",
       " 'recommit',\n",
       " 'railway',\n",
       " 'wunt',\n",
       " 'extent',\n",
       " 'livedin',\n",
       " 'chou',\n",
       " 'dkwab',\n",
       " 'luxor',\n",
       " 'reclusive',\n",
       " 'gotto',\n",
       " 'twitchy',\n",
       " 'widow',\n",
       " 'wouldntve',\n",
       " 'muacks',\n",
       " 'loody',\n",
       " 'massively',\n",
       " 'garmin',\n",
       " 'texmex',\n",
       " 'kale',\n",
       " 'visualization',\n",
       " 'founnders',\n",
       " 'jag',\n",
       " 'roni',\n",
       " 'intrams',\n",
       " 'westinpda',\n",
       " 'healy',\n",
       " 'ouble',\n",
       " 'waxed',\n",
       " 'shockin',\n",
       " 'porfolio',\n",
       " 'houers',\n",
       " 'enlazado',\n",
       " 'maneki',\n",
       " 'handsanitizer',\n",
       " 'finicky',\n",
       " 'ragious',\n",
       " 'unseen',\n",
       " 'guacomole',\n",
       " 'acquitted',\n",
       " 'adventue',\n",
       " 'shyt',\n",
       " 'homekit',\n",
       " 'gain',\n",
       " 'spitting',\n",
       " 'agk',\n",
       " 'furries',\n",
       " 'lasagna',\n",
       " 'iphoneredoing',\n",
       " 'mortuary',\n",
       " 'papii',\n",
       " 'offending',\n",
       " 'sidecar',\n",
       " 'aun',\n",
       " 'jmacs',\n",
       " 'goitn',\n",
       " 'jen',\n",
       " 'livingroom',\n",
       " 'choreography',\n",
       " 'amici',\n",
       " 'mooood',\n",
       " 'carolina',\n",
       " 'fooked',\n",
       " 'anyfinkk',\n",
       " 'asyadeeq',\n",
       " 'centered',\n",
       " 'bubur',\n",
       " 'apace',\n",
       " 'berty',\n",
       " 'ctp',\n",
       " 'harass',\n",
       " 'quinten',\n",
       " 'brokeback',\n",
       " 'yank',\n",
       " 'rental',\n",
       " 'veranda',\n",
       " 'mcmeeting',\n",
       " 'amazming',\n",
       " 'logitech',\n",
       " 'prerc',\n",
       " 'thingys',\n",
       " 'ajung',\n",
       " 'privledges',\n",
       " 'hughh',\n",
       " 'sweetener',\n",
       " 'arising',\n",
       " 'shine',\n",
       " 'coffer',\n",
       " 'uglylooking',\n",
       " 'penetration',\n",
       " 'nightaholic',\n",
       " 'thxthx',\n",
       " 'brightonpissup',\n",
       " 'bymyself',\n",
       " 'empress',\n",
       " 'instudio',\n",
       " 'olympic',\n",
       " 'sarcasticly',\n",
       " 'addie',\n",
       " 'flirtatious',\n",
       " 'cusp',\n",
       " 'talkative',\n",
       " 'pregaming',\n",
       " 'cuppla',\n",
       " 'ricafoort',\n",
       " 'shalom',\n",
       " 'tapedeck',\n",
       " 'ringin',\n",
       " 'ampd',\n",
       " 'abouts',\n",
       " 'ramblings',\n",
       " 'eternal',\n",
       " 'bopsyxz',\n",
       " 'aquired',\n",
       " 'inapt',\n",
       " 'liguistic',\n",
       " 'pear',\n",
       " 'lastnight',\n",
       " 'guud',\n",
       " 'levity',\n",
       " 'lunatic',\n",
       " 'report',\n",
       " 'lipgloss',\n",
       " 'rotates',\n",
       " 'haselnuth',\n",
       " 'brianaa',\n",
       " 'loris',\n",
       " 'lordd',\n",
       " 'ludicrous',\n",
       " 'posibly',\n",
       " 'puttanesca',\n",
       " 'tinatamad',\n",
       " 'twarriage',\n",
       " 'cmdd',\n",
       " 'vodaphone',\n",
       " 'colander',\n",
       " 'tragically',\n",
       " 'aurevoir',\n",
       " 'experiencing',\n",
       " 'producing',\n",
       " 'hightemperature',\n",
       " 'delusional',\n",
       " 'babysitting',\n",
       " 'macknightwahlbergwood',\n",
       " 'edo',\n",
       " 'voiceover',\n",
       " 'coffeemaker',\n",
       " 'tflw',\n",
       " 'syndrone',\n",
       " 'corvette',\n",
       " 'expo',\n",
       " 'liaw',\n",
       " 'cambridgeshire',\n",
       " 'slob',\n",
       " 'jhajha',\n",
       " 'theives',\n",
       " 'atunci',\n",
       " 'tuna',\n",
       " 'guillemot',\n",
       " 'taylena',\n",
       " 'gloria',\n",
       " 'rrawwr',\n",
       " 'kdkdkdkd',\n",
       " 'southamerica',\n",
       " 'atmospheremongering',\n",
       " 'annette',\n",
       " 'extort',\n",
       " 'rawkss',\n",
       " 'resturants',\n",
       " 'absorb',\n",
       " 'bestestfrannds',\n",
       " 'xuan',\n",
       " 'cmh',\n",
       " 'millionn',\n",
       " 'funda',\n",
       " 'tamiori',\n",
       " 'rickrolled',\n",
       " 'encrypt',\n",
       " 'knockoff',\n",
       " 'anaversiry',\n",
       " 'song',\n",
       " 'viiel',\n",
       " 'painless',\n",
       " 'underpar',\n",
       " 'hahahahahah',\n",
       " 'tahitian',\n",
       " 'pweety',\n",
       " 'wegmans',\n",
       " 'stephs',\n",
       " 'certain',\n",
       " 'savusavu',\n",
       " 'tmorrow',\n",
       " 'breakingg',\n",
       " 'piston',\n",
       " 'rthx',\n",
       " 'whohoo',\n",
       " 'bestellt',\n",
       " 'kanji',\n",
       " 'eircom',\n",
       " 'toher',\n",
       " 'fortnight',\n",
       " 'shaina',\n",
       " 'wallis',\n",
       " 'gyrl',\n",
       " 'daan',\n",
       " 'tocome',\n",
       " 'consome',\n",
       " 'geekin',\n",
       " 'cinnabons',\n",
       " 'skyhd',\n",
       " 'calamity',\n",
       " 'andee',\n",
       " 'kirsten',\n",
       " 'cooger',\n",
       " 'unfussed',\n",
       " 'bidding',\n",
       " 'cheri',\n",
       " 'purrd',\n",
       " 'heavy',\n",
       " 'llaman',\n",
       " 'destress',\n",
       " 'pampanga',\n",
       " 'penultimate',\n",
       " 'elijah',\n",
       " 'quinoa',\n",
       " 'nclex',\n",
       " 'caff',\n",
       " 'workking',\n",
       " 'mission',\n",
       " 'tivo',\n",
       " 'notaperv',\n",
       " 'sheepdah',\n",
       " 'ponos',\n",
       " 'waggamammas',\n",
       " 'whitaker',\n",
       " 'rippen',\n",
       " 'calhouns',\n",
       " 'twilightt',\n",
       " 'charismatic',\n",
       " 'rhetorical',\n",
       " 'iaok',\n",
       " 'lodging',\n",
       " 'fabs',\n",
       " 'terminus',\n",
       " 'leveled',\n",
       " 'mozambique',\n",
       " 'eportfolios',\n",
       " 'sixtahs',\n",
       " 'geri',\n",
       " 'reprot',\n",
       " 'twist',\n",
       " 'gopher',\n",
       " 'tomorro',\n",
       " 'wallowing',\n",
       " 'gansta',\n",
       " 'iits',\n",
       " 'unwelcome',\n",
       " 'eastwick',\n",
       " 'jaah',\n",
       " 'redbreast',\n",
       " 'sucessfull',\n",
       " 'clayton',\n",
       " 'mich',\n",
       " 'khit',\n",
       " 'chalkidiki',\n",
       " 'pipol',\n",
       " 'relistic',\n",
       " 'ngt',\n",
       " 'midhurst',\n",
       " 'zacquisha',\n",
       " 'wannted',\n",
       " 'arrogant',\n",
       " 'doubling',\n",
       " 'unpack',\n",
       " 'fleece',\n",
       " 'hadt',\n",
       " 'carolines',\n",
       " 'chaching',\n",
       " 'wwoops',\n",
       " 'edt',\n",
       " 'awwh',\n",
       " 'canyon',\n",
       " 'employed',\n",
       " 'pleeaasee',\n",
       " 'cã',\n",
       " 'snkrdivamob',\n",
       " 'cudis',\n",
       " 'kapuso',\n",
       " 'bakersfield',\n",
       " 'intentionally',\n",
       " 'lovebugg',\n",
       " 'sunon',\n",
       " 'yicket',\n",
       " 'brods',\n",
       " 'picard',\n",
       " 'benneh',\n",
       " 'alam',\n",
       " 'lhriad',\n",
       " 'ruse',\n",
       " 'webinar',\n",
       " 'johannson',\n",
       " 'os',\n",
       " 'suds',\n",
       " 'vannak',\n",
       " 'missconfigured',\n",
       " 'razorlightness',\n",
       " 'goest',\n",
       " 'tillykke',\n",
       " 'optimist',\n",
       " 'cbs',\n",
       " 'aritzia',\n",
       " 'mara',\n",
       " 'friendfeed',\n",
       " 'nlt',\n",
       " 'pinkly',\n",
       " 'ganging',\n",
       " 'cardi',\n",
       " 'seconde',\n",
       " 'exbooty',\n",
       " 'minne',\n",
       " 'twitli',\n",
       " 'killa',\n",
       " 'babysittin',\n",
       " 'provide',\n",
       " 'deefinately',\n",
       " 'churching',\n",
       " 'tri',\n",
       " 'hua',\n",
       " 'soop',\n",
       " 'snad',\n",
       " 'belun',\n",
       " 'mrng',\n",
       " 'database',\n",
       " 'crouch',\n",
       " 'chocolateno',\n",
       " 'solved',\n",
       " 'receiver',\n",
       " 'afghan',\n",
       " 'audit',\n",
       " 'tomorohoping',\n",
       " 'fogbugz',\n",
       " 'mcallen',\n",
       " 'uploader',\n",
       " 'cuntry',\n",
       " 'cabdriving',\n",
       " 'pisstake',\n",
       " 'riseup',\n",
       " 'nghe',\n",
       " 'salana',\n",
       " 'tasteless',\n",
       " 'shhiitt',\n",
       " 'differnce',\n",
       " 'luverr',\n",
       " 'rightwing',\n",
       " 'frewns',\n",
       " 'malayalee',\n",
       " 'invied',\n",
       " 'scrabble',\n",
       " 'comluv',\n",
       " 'happysunshiine',\n",
       " 'losted',\n",
       " 'plina',\n",
       " 'sabudana',\n",
       " 'macchiato',\n",
       " 'cncled',\n",
       " 'wrth',\n",
       " 'deadpool',\n",
       " 'blazing',\n",
       " 'crest',\n",
       " 'lift',\n",
       " 'hefeweizens',\n",
       " 'parodying',\n",
       " 'psychopath',\n",
       " 'lineholders',\n",
       " 'margate',\n",
       " 'poem',\n",
       " 'naslunds',\n",
       " 'chuckran',\n",
       " 'eso',\n",
       " 'gamestate',\n",
       " 'alexisonfire',\n",
       " 'reached',\n",
       " 'liipers',\n",
       " 'thes',\n",
       " 'camzi',\n",
       " 'mgrs',\n",
       " 'tgt',\n",
       " 'dp',\n",
       " 'glove',\n",
       " 'samaa',\n",
       " 'reloaded',\n",
       " 'scoffed',\n",
       " 'urin',\n",
       " 'perverted',\n",
       " 'efficacy',\n",
       " 'qualifying',\n",
       " 'fritzl',\n",
       " 'flugtag',\n",
       " ...}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#word_set = set(word_set)\n",
    "word_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "829f4c96-e106-4e38-874a-3cd900ca351d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200000"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_documents = len(requiredTweetData)\n",
    "total_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0cd182c1-d9a4-4e6f-8eb1-2b225b5a7e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating an index for each word in our vocab.\n",
    "index_dict = {} #Dictionary to store index for each word\n",
    "i = 0\n",
    "for word in word_set:\n",
    "    index_dict[word] = i\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7490e9b-3c37-4fe9-8d58-78af5bc476b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a count dictionary\n",
    " \n",
    "def count_dict(sentences):\n",
    "    word_count = {}\n",
    "    for word in word_set:\n",
    "        word_count[word] = 0\n",
    "        for sent in sentences:\n",
    "            if word in sent:\n",
    "                word_count[word] += 1\n",
    "    return word_count\n",
    " \n",
    "word_count = count_dict(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2081f8ae-c517-47d2-b93a-df16473c3773",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Term Frequency\n",
    "def termfreq(document, word):\n",
    "    N = len(document)\n",
    "    occurance = len([token for token in document if token == word])\n",
    "    return occurance/N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beee9d41-8e60-48a8-acb3-77cd071e7874",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inverse Document Frequency\n",
    " \n",
    "def inverse_doc_freq(word):\n",
    "    try:\n",
    "        word_occurance = word_count[word] + 1\n",
    "    except:\n",
    "        word_occurance = 1\n",
    "    return np.log(total_documents/word_occurance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e36c5a6-9a64-4272-962a-82424a121d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_idf(sentence):\n",
    "    tf_idf_vec = np.zeros((len(word_set),))\n",
    "    for word in sentence:\n",
    "        tf = termfreq(sentence,word)\n",
    "        idf = inverse_doc_freq(word)\n",
    "         \n",
    "        value = tf*idf\n",
    "        tf_idf_vec[index_dict[word]] = value \n",
    "    return tf_idf_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e17a11c-9323-4c6a-a184-efb18125011c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TF-IDF Encoded text corpus\n",
    "vectors = []\n",
    "for sent in sentences:\n",
    "    vec = tf_idf(sent)\n",
    "    vectors.append(vec)\n",
    "\n",
    "print(vectors[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fada7cec-457a-43bd-8a09-2a6397c9df9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
